{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmo8gx9_28fV"
      },
      "source": [
        "# Project Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nY4jMhAM28BA",
        "outputId": "7765846b-4fd8-4a8a-8acf-8949f4db5789"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets scikit-learn torch datasets bertviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWL23IPA1p8T",
        "outputId": "eba26516-8304-4555-e282-f3cdb6545b70"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer, EarlyStoppingCallback\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.nn.functional import softmax\n",
        "from datasets import load_dataset\n",
        "from bertviz import head_view\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# Load dataset\n",
        "train_datasets = load_dataset('ag_news', split='train')\n",
        "test_dataset = load_dataset('ag_news', split='test')\n",
        "\n",
        "# Split into training and validation dataset\n",
        "train_val_split = train_datasets.train_test_split(test_size=0.2, seed=42)\n",
        "train_data = train_val_split['train']\n",
        "val_data = train_val_split['test']\n",
        "\n",
        "print(\"Full training dataset\", len(train_datasets))\n",
        "print(\"\\nTraining dataset:\", train_data)\n",
        "print(\"Validation dataset:\", val_data)\n",
        "print(\"Test dataset:\", test_dataset)\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
        "model = BertModel.from_pretrained(\"google-bert/bert-base-uncased\")\n",
        "\n",
        "# Move the model to GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(f\"\\nBERT tokenizer and model loaded onto {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "H2K6sZb6ofU5",
        "outputId": "a240399d-220b-4bcf-f252-c4710c3c87e8"
      },
      "outputs": [],
      "source": [
        "# Data distribution\n",
        "\n",
        "def plot_label_distribution(dataset, title):\n",
        "    # Convert to DataFrame for easier manipulation\n",
        "    df = pd.DataFrame(dataset)\n",
        "    label_counts = df['label'].value_counts().sort_index()\n",
        "    label_names = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.barplot(x=label_names, y=label_counts.values)\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Count')\n",
        "    plt.xlabel('Label')\n",
        "    plt.ylim(0, max(label_counts.values) * 1.1)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_label_distribution(train_data, \"Training Set Label Distribution\")\n",
        "plot_label_distribution(val_data, \"Validation Set Label Distribution\")\n",
        "plot_label_distribution(test_dataset, \"Test Set Label Distribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bypr7PCiJqQo"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4f8sQLFCiGM"
      },
      "outputs": [],
      "source": [
        "def knn_hyperparameter_tuning(X_train, y_train, X_val, y_val, k_values=[1, 3, 5, 7, 9, 11]):\n",
        "    best_k = None\n",
        "    best_acc = 0.0\n",
        "    acc_dict = {}\n",
        "\n",
        "    for k in k_values:\n",
        "        knn = KNeighborsClassifier(n_neighbors=k)\n",
        "        knn.fit(X_train, y_train)\n",
        "        val_preds = knn.predict(X_val)\n",
        "        acc = accuracy_score(y_val, val_preds)\n",
        "        acc_dict[k] = acc\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_k = k\n",
        "\n",
        "    return best_k, best_acc, acc_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXHxLIewJn1b"
      },
      "outputs": [],
      "source": [
        "def tokenize(item):\n",
        "    return tokenizer(item[\"text\"], truncation=True, padding=\"max_length\", max_length=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUS9YydSxnUS"
      },
      "outputs": [],
      "source": [
        "def save_model(model, tokenizer, path=\"bert-finetuned\"):\n",
        "    model.save_pretrained(path)\n",
        "    tokenizer.save_pretrained(path)\n",
        "\n",
        "def load_model(path=\"bert-finetuned\"):\n",
        "    if os.path.exists(path):\n",
        "        model = BertForSequenceClassification.from_pretrained(path)\n",
        "        tokenizer = BertTokenizer.from_pretrained(path)\n",
        "        return model, tokenizer\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"No saved model at: {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zq4mwBgsxzbj"
      },
      "outputs": [],
      "source": [
        "def save_features(X_train, y_train, X_test, y_test, prefix=\"mean\", directory=\"features_val\"):\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    np.save(os.path.join(directory, f\"X_train_{prefix}.npy\"), X_train)\n",
        "    np.save(os.path.join(directory, f\"y_train_{prefix}.npy\"), y_train)\n",
        "    np.save(os.path.join(directory, f\"X_test_{prefix}.npy\"), X_test)\n",
        "    np.save(os.path.join(directory, f\"y_test_{prefix}.npy\"), y_test)\n",
        "\n",
        "def load_features(prefix=\"mean\", directory=\"features_val\"):\n",
        "    try:\n",
        "        X_train = np.load(os.path.join(directory, f\"X_train_{prefix}.npy\"))\n",
        "        y_train = np.load(os.path.join(directory, f\"y_train_{prefix}.npy\"))\n",
        "        X_test = np.load(os.path.join(directory, f\"X_test_{prefix}.npy\"))\n",
        "        y_test = np.load(os.path.join(directory, f\"y_test_{prefix}.npy\"))\n",
        "        return X_train, y_train, X_test, y_test\n",
        "    except FileNotFoundError:\n",
        "        return None, None, None, None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4INU0Mwv5E2e"
      },
      "source": [
        "# Task 3 - Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwjDa1Xo4Y-L"
      },
      "source": [
        "## Task 3.1 - Probing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvzX3Bjr7-RL"
      },
      "outputs": [],
      "source": [
        "def extract_features(dataset, strategy=\"cls\", max_samples=None):\n",
        "    features, labels = [], []\n",
        "    for i, item in tqdm(enumerate(dataset), total=min(len(dataset), max_samples or len(dataset))):\n",
        "        if max_samples and i >= max_samples:\n",
        "            break\n",
        "\n",
        "        inputs = tokenizer(item['text'], return_tensors='pt', padding='max_length',\n",
        "                           truncation=True, max_length=128)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            hidden = outputs.last_hidden_state  # (batch_size, seq_len, hidden_dim)\n",
        "            attention_mask = inputs['attention_mask']\n",
        "\n",
        "            if strategy == \"cls\":\n",
        "                emb = hidden[:, 0, :]\n",
        "            elif strategy == \"first\":\n",
        "                emb = hidden[:, 1, :]  # first after [CLS]\n",
        "            elif strategy == \"last\":\n",
        "                seq_lengths = attention_mask.sum(dim=1)\n",
        "                emb = hidden[range(hidden.size(0)), seq_lengths - 2, :]  # before [SEP]\n",
        "            elif strategy == \"mean\":\n",
        "                masked = hidden * attention_mask.unsqueeze(-1)\n",
        "                sum_ = masked.sum(dim=1)\n",
        "                count = attention_mask.sum(dim=1).unsqueeze(-1)\n",
        "                emb = sum_ / count\n",
        "            else:\n",
        "                raise ValueError(\"Invalid strategy\")\n",
        "\n",
        "        features.append(emb.squeeze().cpu().numpy())\n",
        "        labels.append(item['label'])\n",
        "\n",
        "    return np.array(features), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txlYEo8T8B46",
        "outputId": "f0e73429-0424-4a4c-d37c-44e0424e59f1"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "strategies = [\"cls\", \"first\", \"last\", \"mean\"]\n",
        "k_values = range(1,21)\n",
        "probing_results = {}\n",
        "\n",
        "for strat in strategies:\n",
        "    print(f\"Extracting features using strategy: {strat}\")\n",
        "\n",
        "    X_train, y_train, X_val, y_val = load_features(prefix=f\"{strat}_val\") # Load previously saved features\n",
        "    if X_train is None:\n",
        "        print(\"No saved features found. Extracting...\")\n",
        "        X_train, y_train = extract_features(train_data, strategy=strat, max_samples=4000)  # LARGER MAX_SAMPLES IN FINAL VERSION\n",
        "        X_val, y_val = extract_features(val_data, strategy=strat, max_samples=1000)\n",
        "        save_features(X_train, y_train, X_val, y_val, prefix=f\"{strat}_val\")\n",
        "    else:\n",
        "        print(\"→ Loaded saved features.\")\n",
        "\n",
        "    # KNN\n",
        "    best_k, best_knn_acc, knn_accs = knn_hyperparameter_tuning(X_train, y_train, X_val, y_val, k_values=k_values)\n",
        "\n",
        "    # Logistic Regression\n",
        "    logreg = LogisticRegression(max_iter=1000)\n",
        "    logreg.fit(X_train, y_train)\n",
        "    logreg_acc = accuracy_score(y_val, logreg.predict(X_val))\n",
        "\n",
        "    probing_results [strat] = {\n",
        "        \"logreg\": logreg_acc,\n",
        "        \"knn_best_k\": best_k,\n",
        "        \"knn_acc\": best_knn_acc,\n",
        "        \"knn_all\": knn_accs\n",
        "    }\n",
        "\n",
        "for strat, scores in probing_results .items():\n",
        "    print(f\"{strat:<6} \\t\\t LogReg Acc: {scores['logreg']:.4f} \\t\\t Best K: {scores['knn_best_k']} \\t KNN Acc: {scores['knn_acc']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X-Wcil1YrCbO",
        "outputId": "9f69ff0a-57b7-4f15-add5-b4b9bae8e05b"
      },
      "outputs": [],
      "source": [
        "logreg_scores = [probing_results[s][\"logreg\"] for s in strategies]\n",
        "knn_scores = [probing_results[s][\"knn_acc\"] for s in strategies]\n",
        "\n",
        "df_summary = pd.DataFrame({\n",
        "    \"Embedding Strategy\": strategies,\n",
        "    \"Logistic Regression Accuracy\": logreg_scores,\n",
        "    \"KNN Best Accuracy\": knn_scores\n",
        "})\n",
        "\n",
        "print(\"Table 1: Validation Accuracy by Embedding Strategy and Classifier\")\n",
        "print(df_summary)\n",
        "print(\"\\n\")\n",
        "\n",
        "# -------------------\n",
        "# Table 2: Detailed KNN Accuracies across Different K Values\n",
        "# -------------------\n",
        "rows = []\n",
        "for strat in strategies:\n",
        "    k_acc_dict = probing_results[strat]['knn_all']\n",
        "    for k, acc in k_acc_dict.items():\n",
        "        rows.append({\n",
        "            \"Embedding Strategy\": strat,\n",
        "            \"K\": k,\n",
        "            \"KNN Accuracy\": acc\n",
        "        })\n",
        "\n",
        "df_knn = pd.DataFrame(rows)\n",
        "\n",
        "print(\"Table 2: Validation Accuracy vs. K for Each Embedding Strategy (KNN)\")\n",
        "print(df_knn)\n",
        "\n",
        "# -------------------\n",
        "# You can also plot the data as before:\n",
        "# Plot 1: Bar plot for summary accuracies\n",
        "x = np.arange(len(strategies))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "bars1 = ax.bar(x - width/2, logreg_scores, width, label='Logistic Regression')\n",
        "bars2 = ax.bar(x + width/2, knn_scores, width, label='KNN (Best K)')\n",
        "\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Accuracy by Embedding Strategy and Classifier')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(strategies)\n",
        "ax.set_ylim([0, 1.0])\n",
        "ax.legend()\n",
        "\n",
        "for bar in bars1 + bars2:\n",
        "    height = bar.get_height()\n",
        "    ax.annotate(f'{height:.3f}',\n",
        "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                xytext=(0, 3), textcoords=\"offset points\",\n",
        "                ha='center', va='bottom')\n",
        "\n",
        "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "fig2, ax2 = plt.subplots(figsize=(8, 5))\n",
        "\n",
        "k_values = list(next(iter(probing_results.values()))['knn_all'].keys())\n",
        "for strat in strategies:\n",
        "    k_acc_dict = probing_results[strat]['knn_all']\n",
        "    k_vals = list(k_acc_dict.keys())\n",
        "    accs = list(k_acc_dict.values())\n",
        "    ax2.plot(k_vals, accs, marker='o', label=f'{strat}')\n",
        "\n",
        "ax2.set_xlabel(\"Number of Neighbors (K)\")\n",
        "ax2.set_ylabel(\"Validation Accuracy\")\n",
        "ax2.set_title(\"KNN Accuracy vs. K for Each Embedding Strategy\")\n",
        "ax2.set_xticks(k_values)\n",
        "ax2.set_ylim([0, 1.0])\n",
        "ax2.legend(title=\"Strategy\")\n",
        "ax2.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjYsG30SJV6i"
      },
      "source": [
        "## Task 3.2 - Fine-Tuning BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "b116aaf73a7c4f1793726b4460341f8e",
            "bbdd1ee4d99a4d2db4f3cfb0201bfcbd",
            "66ef9b02ae5d4067aae28bc6919f68f2",
            "15b25baad9444a5890cb9bf4a3713c9e",
            "60c00793e44a4399b41cef4f2ecbb600",
            "2f10195423504e9bbdfa86bd358a427e",
            "cd1d84feddaf4355ab73508032525cfc",
            "74cddab1927845cc95c903786de85ee2",
            "fd5b7bc9541d4c849f4bae1e25f59a7a",
            "5c74986fc8f743919ed52d232e90d50d",
            "b936bc1e7fab4e3e8bbcaf5ac3c5961d",
            "5bd77e3b0bb8452aba6e1ba6e220c150",
            "123ce7ead7ad49ef8afb4238fa2c6b35",
            "152673a2c4c24fd38e21270d76586435",
            "a9e59c17ee2b4d2ba655681eb86b9a74",
            "aa7f169fb8d248fd87098b4fe68a7212",
            "6bf3171f03284c339ec8095a73f24e45",
            "67ca81f007f941d1bf1eae46dbb0bfd5",
            "8de0738fa27b4cfa9222901dc99c38fb",
            "5560a7916359473bb707d1df2522cf61",
            "044a8e421a5e4cef8b40d4faa7f52b20",
            "a432a3b4f23a471bbe0ecf24dcf9d058"
          ]
        },
        "id": "b_0rJvrcJcG8",
        "outputId": "cac3553b-cc38-4c18-d1c4-82cd6c9b2715"
      },
      "outputs": [],
      "source": [
        "# Use a subset of the dataset (20k train, 2k val)\n",
        "small_train = train_data.shuffle(seed=42).select(range(20000))\n",
        "small_val = val_data.shuffle(seed=42).select(range(2000))\n",
        "\n",
        "tokenized_train = small_train.map(tokenize, batched=True)\n",
        "tokenized_val = small_val.map(tokenize, batched=True)\n",
        "\n",
        "tokenized_train = tokenized_train.rename_column(\"label\", \"labels\")\n",
        "tokenized_val = tokenized_val.rename_column(\"label\", \"labels\")\n",
        "tokenized_train.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "tokenized_val.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQqVGCLzXfzc"
      },
      "source": [
        "We chose to use Hugging Face’s transformers library for fine-tuning, instead of the model setup provided in the assignment instructions. This implementation allows full fine-tuning of all BERT parameters along with an added classification head.\n",
        "\n",
        "Reference: https://huggingface.co/docs/transformers/en/training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "vtZ0UW0TJEyZ",
        "outputId": "c572749d-3484-4c13-f199-69fed821222f"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    finetune_model, tokenizer = load_model()\n",
        "    print(\"Loaded fine-tuned model from disk.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"No saved model found. Fine-tuning from scratch...\\n\")\n",
        "\n",
        "    finetune_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=4)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./bert_checkpoints\",\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        logging_strategy=\"epoch\",\n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        num_train_epochs=5,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir=\"./bert_logs\",\n",
        "        load_best_model_at_end=True,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=finetune_model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train,\n",
        "        eval_dataset=tokenized_val,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=lambda p: {\"accuracy\": (p.predictions.argmax(axis=1) == p.label_ids).mean()},\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    save_model(finetune_model, tokenizer)\n",
        "\n",
        "if 'trainer' not in locals():\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./bert_checkpoints\",\n",
        "        per_device_eval_batch_size=16,\n",
        "        do_train=False,\n",
        "        do_eval=True,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "    trainer = Trainer(\n",
        "        model=finetune_model,\n",
        "        args=training_args,\n",
        "        eval_dataset=tokenized_val,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=lambda p: {\"accuracy\": (p.predictions.argmax(axis=1) == p.label_ids).mean()}\n",
        "    )\n",
        "\n",
        "bert_results = trainer.evaluate()\n",
        "print(f\"Validation Accuracy after fine-tuning: {bert_results['eval_accuracy']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4SXPLOOjedK"
      },
      "source": [
        "## Task 3.3 - Classification Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ibCFcVkjjqC",
        "outputId": "e2f75f5e-27df-4978-ea81-6ad395c6e68a"
      },
      "outputs": [],
      "source": [
        "best_strategy = max(probing_results, key=lambda s: max(probing_results[s]['logreg'], probing_results[s]['knn_acc']))\n",
        "print(f\"Best embedding strategy: {best_strategy}\")\n",
        "\n",
        "X_full_train, y_full_train, X_test, y_test = load_features(prefix=best_strategy, directory=\"features_test\")\n",
        "if X_full_train is None:\n",
        "    print(\"No saved features found in 'features_test'. Extracting now...\")\n",
        "    X_full_train, y_full_train = extract_features(train_datasets, strategy=best_strategy)\n",
        "    X_test, y_test = extract_features(test_dataset, strategy=best_strategy)\n",
        "    save_features(X_full_train, y_full_train, X_test, y_test, prefix=best_strategy, directory=\"features_test\")\n",
        "else:\n",
        "    print(\"Loaded features from 'features_test'.\")\n",
        "\n",
        "print(f\"\\n===  KNN and Logistic Regression Test Accuracy ===\")\n",
        "best_k = probing_results[best_strategy]['knn_best_k']\n",
        "knn_final = KNeighborsClassifier(n_neighbors=best_k)\n",
        "knn_final.fit(X_full_train, y_full_train)\n",
        "knn_test_acc = accuracy_score(y_test, knn_final.predict(X_test))\n",
        "print(f\"KNN Test Accuracy (strategy: {best_strategy}, k={best_k}): {knn_test_acc:.4f}\")\n",
        "\n",
        "logreg_final = LogisticRegression(max_iter=1000)\n",
        "logreg_final.fit(X_full_train, y_full_train)\n",
        "logreg_test_acc = accuracy_score(y_test, logreg_final.predict(X_test))\n",
        "print(f\"Logistic Regression Test Accuracy (strategy: {best_strategy}): {logreg_test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "fc3d40262054420f91c3049961db86e6",
            "0a88627209de44bb973b37db53f2517f",
            "58fa11a9dfc74383be933c220366d6c5",
            "1620b6932566425ca3703f3eb4a455f6",
            "77f3a92941944678b0e087f2532ceb99",
            "16152bbc4bbe470bbfd448759b187132",
            "7bbe26261be44b34ab1e9e48eef3108b",
            "e7e5e8ed3649435b80709f0db08b7001",
            "f938436ef1b54d388d69865777758ec3",
            "15ed126189e54e7280631cdede312cfb",
            "9b9ff6307d9f4550820cbb4130a9e224"
          ]
        },
        "id": "TJ1eZVk7jy-5",
        "outputId": "10e0dea1-1937-4034-b7a4-d05685e5d4f5"
      },
      "outputs": [],
      "source": [
        "tokenized_test = test_dataset.map(tokenize, batched=True)\n",
        "tokenized_test = tokenized_test.rename_column(\"label\", \"labels\")\n",
        "tokenized_test.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "fine_tune_results = trainer.evaluate(tokenized_test)\n",
        "fine_tune_test_acc = fine_tune_results[\"eval_accuracy\"]\n",
        "print(f\"Fine-tuned BERT Test Accuracy: {fine_tune_test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "5hZlhqnDsupA",
        "outputId": "4d7cc92e-6f54-450b-a14f-ddd448cedd4b"
      },
      "outputs": [],
      "source": [
        "labels = [\"KNN (Probing)\", \"LogReg (Probing)\", \"Fine-tuned BERT\"]\n",
        "test_accuracies = [knn_test_acc, logreg_test_acc, fine_tune_test_acc]\n",
        "\n",
        "x = np.arange(len(labels))\n",
        "width = 0.7\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 5))\n",
        "bars = ax.bar(x, test_accuracies, width, color=[\"blue\", \"green\", \"red\"])\n",
        "\n",
        "ax.set_ylabel(\"Test Accuracy\")\n",
        "ax.set_title(\"Test Accuracies for Best Probing Strategy vs Fine-Tuned BERT\")\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.set_ylim([0.7, 1.0])\n",
        "\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    ax.annotate(f\"{height:.4f}\",\n",
        "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                xytext=(0, 3),\n",
        "                textcoords=\"offset points\",\n",
        "                ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "E7G9MvORkq6Z",
        "outputId": "c0ea351d-8895-48a7-e2f3-bf38ce1e3eb3"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Do we need to report the test accuracy for each strategy? Or just the best one?\n",
        "Phrasing is a little awkward.\n",
        "\n",
        "If the former, we can modify this code block from\n",
        "using (currently) validation accuracy to test accuracy for each strategy.\n",
        "'''\n",
        "\n",
        "# comparison_data = []\n",
        "# for strat, accs in probing_results.items():\n",
        "#     logreg = accs.get(\"logreg\", \"-\")\n",
        "#     knn = accs.get(\"knn_acc\", \"-\")\n",
        "\n",
        "#     comparison_data.append({\n",
        "#         \"Strategy\": strat,\n",
        "#         \"LogReg Test Acc\": f\"{logreg:.4f}\" if isinstance(logreg, float) else logreg,\n",
        "#         \"KNN Test Acc\": f\"{knn:.4f}\" if isinstance(knn, float) else knn\n",
        "#     })\n",
        "\n",
        "# comparison_df = pd.DataFrame(comparison_data)\n",
        "# comparison_df[\"_sort\"] = pd.to_numeric(comparison_df[\"LogReg Test Acc\"], errors=\"coerce\")\n",
        "# comparison_df = comparison_df.sort_values(by=\"_sort\", ascending=False).drop(columns=\"_sort\")\n",
        "\n",
        "# print(\"=== Multiclass Classification Test Accuracy Comparison ===\")\n",
        "# print(comparison_df)\n",
        "\n",
        "# print(\"\\n=== Fine-tuned BERT Test Accuracy ===\")\n",
        "# print(f\"LogReg Test Acc: {fine_tune_test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thqJc3KOmz1p"
      },
      "source": [
        "## Task 3.4 - Attention Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4z7iPnnt0ai"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "from bertviz import head_view, model_view\n",
        "import seaborn as sns\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-finetuned\")\n",
        "\n",
        "bert_attention_model = BertModel.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    output_attentions=True,\n",
        "    attn_implementation=\"eager\"\n",
        ")\n",
        "bert_attention_model.eval()\n",
        "bert_attention_model.to(device)\n",
        "\n",
        "clf_model = BertForSequenceClassification.from_pretrained(\"bert-finetuned\")\n",
        "clf_model.eval()\n",
        "clf_model.to(device)\n",
        "\n",
        "\n",
        "def get_model_prediction(text, tokenizer, model, device):\n",
        "    \"\"\"\n",
        "    Tokenizes and runs the given model (which outputs attentions) on the text.\n",
        "    Returns:\n",
        "      - pred_label: the predicted label.\n",
        "      - confidence: the softmax confidence for that label.\n",
        "      - attentions: the attention outputs (if available).\n",
        "      - input_ids: tokenized input IDs.\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128\n",
        "    )\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, output_attentions=True)\n",
        "    logits = outputs.logits\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    pred_label = torch.argmax(probs, dim=-1).item()\n",
        "    confidence = probs[0, pred_label].item()\n",
        "    return pred_label, confidence, outputs.attentions, inputs[\"input_ids\"]\n",
        "\n",
        "def predict_label_with_prob(text):\n",
        "    \"\"\"\n",
        "    Uses the classification model to get prediction and confidence.\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128\n",
        "    )\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = clf_model(**inputs)\n",
        "        probs = F.softmax(outputs.logits, dim=1)\n",
        "        pred = torch.argmax(probs, dim=1).item()\n",
        "        max_prob = probs[0, pred].item()\n",
        "    return pred, max_prob\n",
        "\n",
        "def visualize_heatmap(text, tokenizer, model, device, layer=8, head=0):\n",
        "    \"\"\"\n",
        "    Runs the model on a given text sample and extracts attention from the specified\n",
        "    layer and head. Then plots a heatmap (using seaborn) of the top 10 tokens (by attention)\n",
        "    attended to by the [CLS] token.\n",
        "    \"\"\"\n",
        "    pred_label, confidence, attentions, input_ids = get_model_prediction(text, tokenizer, model, device)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "\n",
        "    attn_matrix = attentions[layer][0, head].cpu().numpy()\n",
        "    cls_attention = attn_matrix[0]\n",
        "\n",
        "    token_indices = list(range(1, len(tokens)))\n",
        "    sorted_indices = sorted(token_indices, key=lambda i: cls_attention[i], reverse=True)\n",
        "    top_indices = sorted_indices[:10]\n",
        "\n",
        "    top_tokens = [tokens[i] for i in top_indices]\n",
        "    top_values = [cls_attention[i] for i in top_indices]\n",
        "\n",
        "    plt.figure(figsize=(10, 1.5))\n",
        "    sns.heatmap([top_values], annot=True, xticklabels=top_tokens, yticklabels=[\"[CLS]\"], cmap=\"viridis\")\n",
        "    plt.title(f\"Attention from [CLS] (Layer {layer+1}, Head {head})\\nPredicted: {pred_label} | Confidence: {confidence:.2f}\")\n",
        "    plt.show()\n",
        "\n",
        "def visualize_attention(text):\n",
        "    \"\"\"\n",
        "    Obtains the full attention outputs from bert_attention_model and launches\n",
        "    the interactive head_view visualization.\n",
        "    Ensures that tensors are on the correct device.\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors='pt',\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_attention_model(**inputs)\n",
        "    attention = tuple(a.cpu() for a in outputs.attentions)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "    head_view(attention, tokens)\n",
        "\n",
        "def select_examples(test_dataset, tokenizer, model, device, conf_threshold=0.9, label_list=[0,1,2,3]):\n",
        "    \"\"\"\n",
        "    Iterates over test_dataset and selects, for each label in label_list:\n",
        "      - One correctly predicted example (with confidence >= conf_threshold).\n",
        "      - One incorrectly predicted example (with confidence >= conf_threshold).\n",
        "\n",
        "    Returns two dictionaries:\n",
        "      correct_examples[label] and incorrect_examples[label], for each label in label_list.\n",
        "    \"\"\"\n",
        "    correct_examples = {label: None for label in label_list}\n",
        "    incorrect_examples = {label: None for label in label_list}\n",
        "\n",
        "    for example in tqdm(test_dataset, desc=\"Selecting examples for all labels\"):\n",
        "        text = example[\"text\"]\n",
        "        true_label = example[\"label\"]\n",
        "        if true_label not in label_list:\n",
        "            continue\n",
        "        pred_label, confidence, _, _ = get_model_prediction(text, tokenizer, model, device)\n",
        "        if confidence < conf_threshold:\n",
        "            continue\n",
        "        if pred_label == true_label:\n",
        "            if correct_examples[true_label] is None:\n",
        "                correct_examples[true_label] = text\n",
        "        else:\n",
        "            if incorrect_examples[true_label] is None:\n",
        "                incorrect_examples[true_label] = text\n",
        "        # Break early if we have one each for all labels.\n",
        "        if all(correct_examples[label] is not None for label in label_list) and \\\n",
        "           all(incorrect_examples[label] is not None for label in label_list):\n",
        "            break\n",
        "\n",
        "    return correct_examples, incorrect_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nEJQeObnxKl",
        "outputId": "241cdd56-e584-4652-d91e-12eb8fdc5918"
      },
      "outputs": [],
      "source": [
        "test_dataset = load_dataset('ag_news', split='test')\n",
        "\n",
        "correct_dict, incorrect_dict = select_examples(test_dataset, tokenizer, clf_model, device, conf_threshold=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN0ZYasanjn9"
      },
      "source": [
        "### Label 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uArSdszvAtx4",
        "outputId": "c735b4a6-a8dd-4a3f-c622-8470f4f960bf"
      },
      "outputs": [],
      "source": [
        "print(\"=== Analysis for Label 0 ===\")\n",
        "if correct_dict[0]:\n",
        "    print(\"Correctly Predicted Example for Label 0:\")\n",
        "    print(correct_dict[0][:] + \"...\")\n",
        "    visualize_heatmap(correct_dict[0], tokenizer, clf_model, device, layer=11, head=0)\n",
        "    visualize_attention(correct_dict[0])\n",
        "else:\n",
        "    print(\"No correctly predicted example found for label 0.\")\n",
        "\n",
        "if incorrect_dict[0]:\n",
        "    print(\"\\nIncorrectly Predicted Example for Label 0:\")\n",
        "    print(incorrect_dict[0][:])\n",
        "    visualize_heatmap(incorrect_dict[0], tokenizer, clf_model, device, layer=11, head=0)\n",
        "    visualize_attention(incorrect_dict[0])\n",
        "else:\n",
        "    print(\"No incorrectly predicted example found for label 0.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK4azxxOnfw1"
      },
      "source": [
        "### Label 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ISu_CX1AnKEW",
        "outputId": "91185b28-0019-4a6a-97f2-85835428e0d4"
      },
      "outputs": [],
      "source": [
        "print(\"=== Analysis for Label 1 ===\")\n",
        "if correct_dict[1]:\n",
        "    print(\"Correctly Predicted Example for Label 1:\")\n",
        "    print(correct_dict[1][:] + \"...\")\n",
        "    visualize_heatmap(correct_dict[1], tokenizer, clf_model, device, layer=11, head=0)\n",
        "    visualize_attention(correct_dict[1])\n",
        "else:\n",
        "    print(\"No correctly predicted example found for label 1.\")\n",
        "\n",
        "if incorrect_dict[1]:\n",
        "    print(\"\\nIncorrectly Predicted Example for Label 1:\")\n",
        "    print(incorrect_dict[1][:] + \"...\")\n",
        "    visualize_heatmap(incorrect_dict[1], tokenizer, clf_model, device, layer=11, head=0)\n",
        "    visualize_attention(incorrect_dict[1])\n",
        "else:\n",
        "    print(\"No incorrectly predicted example found for label 1.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pEn6DrRna1o"
      },
      "source": [
        "### Label 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "65oQP8pHnNOd",
        "outputId": "58241496-07e3-4d69-848c-7b4fe1132667"
      },
      "outputs": [],
      "source": [
        "print(\"=== Analysis for Label 2 ===\")\n",
        "if correct_dict[2]:\n",
        "    print(\"Correctly Predicted Example for Label 2:\")\n",
        "    print(correct_dict[2][:] + \"...\")\n",
        "    visualize_heatmap(correct_dict[2], tokenizer, clf_model, device, layer=11, head=0)\n",
        "    visualize_attention(correct_dict[2])\n",
        "else:\n",
        "    print(\"No correctly predicted example found for label 2.\")\n",
        "\n",
        "if incorrect_dict[2]:\n",
        "    print(\"\\nIncorrectly Predicted Example for Label 2:\")\n",
        "    print(incorrect_dict[2][:] + \"...\")\n",
        "    visualize_heatmap(incorrect_dict[2], tokenizer, clf_model, device, layer=11, head=0)\n",
        "    visualize_attention(incorrect_dict[2])\n",
        "else:\n",
        "    print(\"No incorrectly predicted example found for label 2.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NccFQo6annSB"
      },
      "source": [
        "### Label 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7nlKjG77nREc",
        "outputId": "cada9b14-b859-4c0a-b29a-affc9cd7e363"
      },
      "outputs": [],
      "source": [
        "print(\"=== Analysis for Label 3 ===\")\n",
        "if correct_dict[3]:\n",
        "    print(\"Correctly Predicted Example for Label 3:\")\n",
        "    print(correct_dict[3][:] + \"...\")\n",
        "    visualize_heatmap(correct_dict[3], tokenizer, clf_model, device, layer=11, head=0)\n",
        "    visualize_attention(correct_dict[3])\n",
        "else:\n",
        "    print(\"No correctly predicted example found for label 3.\")\n",
        "\n",
        "if incorrect_dict[3]:\n",
        "    print(\"\\nIncorrectly Predicted Example for Label 3:\")\n",
        "    print(incorrect_dict[3][:] + \"...\")\n",
        "    visualize_heatmap(incorrect_dict[3], tokenizer, clf_model, device, layer=11, head=0)\n",
        "    visualize_attention(incorrect_dict[3])\n",
        "else:\n",
        "    print(\"No incorrectly predicted example found for label 3.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATOnw-5DiNkX"
      },
      "source": [
        "# Extra experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g33Ca77IjwIX"
      },
      "outputs": [],
      "source": [
        "def analyze_attention_statistics(text, layer=11, head=0):\n",
        "    pred_label, confidence, attentions, input_ids = get_model_prediction(text, tokenizer, clf_model, device)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "    attn_matrix = attentions[layer][0, head].cpu().numpy()\n",
        "    cls_attn = attn_matrix[0]\n",
        "    cls_attn_excluding_cls = cls_attn[1:]\n",
        "\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.hist(cls_attn_excluding_cls, bins=20, color=\"skyblue\", edgecolor=\"black\")\n",
        "    plt.title(f\"Attention Weight Distribution (Layer {layer+1}, Head {head})\")\n",
        "    plt.xlabel(\"Attention Weight\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.show()\n",
        "\n",
        "def compare_heads(text, layer=11, heads=[0,1,2,3]):\n",
        "    pred_label, confidence, attentions, input_ids = get_model_prediction(text, tokenizer, clf_model, device)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "    plt.figure(figsize=(15, 4))\n",
        "    for i, head in enumerate(heads):\n",
        "        attn_matrix = attentions[layer][0, head].cpu().numpy()\n",
        "        cls_attn = attn_matrix[0]\n",
        "        cls_attn_excluding_cls = cls_attn[1:]\n",
        "        sorted_indices = np.argsort(-cls_attn_excluding_cls)  # descending order\n",
        "        top_indices = sorted_indices[:10] + 1  # adjust indices to include offset for [CLS]\n",
        "        top_tokens = [tokens[i] for i in top_indices]\n",
        "        top_values = cls_attn[top_indices]\n",
        "        plt.subplot(1, len(heads), i+1)\n",
        "        plt.bar(range(len(top_tokens)), top_values, tick_label=top_tokens)\n",
        "        plt.title(f\"Head {head}\\nPred: {pred_label} | Conf: {confidence:.2f}\")\n",
        "        plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VM9gmSYMjUx4",
        "outputId": "8ec57662-122c-40bf-e075-7fdf03dcb250"
      },
      "outputs": [],
      "source": [
        "print(\"=== Analysis for Label 0 ===\")\n",
        "if correct_dict[0]:\n",
        "    print(\"Correctly Predicted Example for Label 0:\")\n",
        "    print(correct_dict[0][:200] + \"...\")\n",
        "    analyze_attention_statistics(correct_dict[0], layer=11, head=0)\n",
        "    compare_heads(correct_dict[0], layer=11, heads=[0,1,2,3])\n",
        "else:\n",
        "    print(\"No correctly predicted example found for label 0.\")\n",
        "\n",
        "if incorrect_dict[0]:\n",
        "    print(\"\\nIncorrectly Predicted Example for Label 0:\")\n",
        "    print(incorrect_dict[0][:200] + \"...\")\n",
        "    analyze_attention_statistics(incorrect_dict[0], layer=11, head=0)\n",
        "    compare_heads(incorrect_dict[0], layer=11, heads=[0,1,2,3])\n",
        "else:\n",
        "    print(\"No incorrectly predicted example found for label 0.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wbqyt0IGjTL8",
        "outputId": "0d246fdc-8391-488c-f757-9e2d2258a71d"
      },
      "outputs": [],
      "source": [
        "print(\"=== Analysis for Label 0 ===\")\n",
        "if correct_dict[0]:\n",
        "    print(\"Correctly Predicted Example for Label 0:\")\n",
        "    print(correct_dict[0][:200] + \"...\")\n",
        "    analyze_attention_statistics(correct_dict[0], layer=11, head=0)\n",
        "    compare_heads(correct_dict[0], layer=11, heads=[0,1,2,3])\n",
        "else:\n",
        "    print(\"No correctly predicted example found for label 0.\")\n",
        "\n",
        "if incorrect_dict[0]:\n",
        "    print(\"\\nIncorrectly Predicted Example for Label 0:\")\n",
        "    print(incorrect_dict[0][:200] + \"...\")\n",
        "    analyze_attention_statistics(incorrect_dict[0], layer=11, head=0)\n",
        "    compare_heads(incorrect_dict[0], layer=11, heads=[0,1,2,3])\n",
        "else:\n",
        "    print(\"No incorrectly predicted example found for label 0.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k4UR3SfFjXj4",
        "outputId": "f5a2bc50-1cbc-47c8-b044-f879c4d2aedc"
      },
      "outputs": [],
      "source": [
        "print(\"=== Analysis for Label 2 ===\")\n",
        "if correct_dict[2]:\n",
        "    print(\"Correctly Predicted Example for Label 2:\")\n",
        "    print(correct_dict[2][:200] + \"...\")\n",
        "    analyze_attention_statistics(correct_dict[2], layer=11, head=0)\n",
        "    compare_heads(correct_dict[2], layer=11, heads=[0,1,2,3])\n",
        "else:\n",
        "    print(\"No correctly predicted example found for label 2.\")\n",
        "\n",
        "if incorrect_dict[2]:\n",
        "    print(\"\\nIncorrectly Predicted Example for Label 2:\")\n",
        "    print(incorrect_dict[2][:200] + \"...\")\n",
        "    analyze_attention_statistics(incorrect_dict[2], layer=11, head=0)\n",
        "    compare_heads(incorrect_dict[2], layer=11, heads=[0,1,2,3])\n",
        "else:\n",
        "    print(\"No incorrectly predicted example found for label 2.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F8zmH62kjY2l",
        "outputId": "bd86f163-c0f0-4c29-b760-c1997077a896"
      },
      "outputs": [],
      "source": [
        "print(\"=== Analysis for Label 3 ===\")\n",
        "if correct_dict[3]:\n",
        "    print(\"Correctly Predicted Example for Label 3:\")\n",
        "    print(correct_dict[3][:200] + \"...\")\n",
        "    analyze_attention_statistics(correct_dict[3], layer=11, head=0)\n",
        "    compare_heads(correct_dict[3], layer=11, heads=[0,1,2,3])\n",
        "else:\n",
        "    print(\"No correctly predicted example found for label 3.\")\n",
        "\n",
        "if incorrect_dict[3]:\n",
        "    print(\"\\nIncorrectly Predicted Example for Label 3:\")\n",
        "    print(incorrect_dict[3][:200] + \"...\")\n",
        "    analyze_attention_statistics(incorrect_dict[3], layer=11, head=0)\n",
        "    compare_heads(incorrect_dict[3], layer=11, heads=[0,1,2,3])\n",
        "else:\n",
        "    print(\"No incorrectly predicted example found for label 3.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Bypr7PCiJqQo"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "044a8e421a5e4cef8b40d4faa7f52b20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a88627209de44bb973b37db53f2517f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16152bbc4bbe470bbfd448759b187132",
            "placeholder": "​",
            "style": "IPY_MODEL_7bbe26261be44b34ab1e9e48eef3108b",
            "value": "Map: 100%"
          }
        },
        "123ce7ead7ad49ef8afb4238fa2c6b35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bf3171f03284c339ec8095a73f24e45",
            "placeholder": "​",
            "style": "IPY_MODEL_67ca81f007f941d1bf1eae46dbb0bfd5",
            "value": "Map: 100%"
          }
        },
        "152673a2c4c24fd38e21270d76586435": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8de0738fa27b4cfa9222901dc99c38fb",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5560a7916359473bb707d1df2522cf61",
            "value": 2000
          }
        },
        "15b25baad9444a5890cb9bf4a3713c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c74986fc8f743919ed52d232e90d50d",
            "placeholder": "​",
            "style": "IPY_MODEL_b936bc1e7fab4e3e8bbcaf5ac3c5961d",
            "value": " 20000/20000 [00:19&lt;00:00, 1160.09 examples/s]"
          }
        },
        "15ed126189e54e7280631cdede312cfb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16152bbc4bbe470bbfd448759b187132": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1620b6932566425ca3703f3eb4a455f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15ed126189e54e7280631cdede312cfb",
            "placeholder": "​",
            "style": "IPY_MODEL_9b9ff6307d9f4550820cbb4130a9e224",
            "value": " 7600/7600 [00:13&lt;00:00, 561.91 examples/s]"
          }
        },
        "2f10195423504e9bbdfa86bd358a427e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5560a7916359473bb707d1df2522cf61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58fa11a9dfc74383be933c220366d6c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7e5e8ed3649435b80709f0db08b7001",
            "max": 7600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f938436ef1b54d388d69865777758ec3",
            "value": 7600
          }
        },
        "5bd77e3b0bb8452aba6e1ba6e220c150": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_123ce7ead7ad49ef8afb4238fa2c6b35",
              "IPY_MODEL_152673a2c4c24fd38e21270d76586435",
              "IPY_MODEL_a9e59c17ee2b4d2ba655681eb86b9a74"
            ],
            "layout": "IPY_MODEL_aa7f169fb8d248fd87098b4fe68a7212"
          }
        },
        "5c74986fc8f743919ed52d232e90d50d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60c00793e44a4399b41cef4f2ecbb600": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66ef9b02ae5d4067aae28bc6919f68f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74cddab1927845cc95c903786de85ee2",
            "max": 20000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd5b7bc9541d4c849f4bae1e25f59a7a",
            "value": 20000
          }
        },
        "67ca81f007f941d1bf1eae46dbb0bfd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bf3171f03284c339ec8095a73f24e45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74cddab1927845cc95c903786de85ee2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77f3a92941944678b0e087f2532ceb99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bbe26261be44b34ab1e9e48eef3108b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8de0738fa27b4cfa9222901dc99c38fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b9ff6307d9f4550820cbb4130a9e224": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a432a3b4f23a471bbe0ecf24dcf9d058": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9e59c17ee2b4d2ba655681eb86b9a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_044a8e421a5e4cef8b40d4faa7f52b20",
            "placeholder": "​",
            "style": "IPY_MODEL_a432a3b4f23a471bbe0ecf24dcf9d058",
            "value": " 2000/2000 [00:01&lt;00:00, 1189.49 examples/s]"
          }
        },
        "aa7f169fb8d248fd87098b4fe68a7212": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b116aaf73a7c4f1793726b4460341f8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bbdd1ee4d99a4d2db4f3cfb0201bfcbd",
              "IPY_MODEL_66ef9b02ae5d4067aae28bc6919f68f2",
              "IPY_MODEL_15b25baad9444a5890cb9bf4a3713c9e"
            ],
            "layout": "IPY_MODEL_60c00793e44a4399b41cef4f2ecbb600"
          }
        },
        "b936bc1e7fab4e3e8bbcaf5ac3c5961d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbdd1ee4d99a4d2db4f3cfb0201bfcbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f10195423504e9bbdfa86bd358a427e",
            "placeholder": "​",
            "style": "IPY_MODEL_cd1d84feddaf4355ab73508032525cfc",
            "value": "Map: 100%"
          }
        },
        "cd1d84feddaf4355ab73508032525cfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7e5e8ed3649435b80709f0db08b7001": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f938436ef1b54d388d69865777758ec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc3d40262054420f91c3049961db86e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a88627209de44bb973b37db53f2517f",
              "IPY_MODEL_58fa11a9dfc74383be933c220366d6c5",
              "IPY_MODEL_1620b6932566425ca3703f3eb4a455f6"
            ],
            "layout": "IPY_MODEL_77f3a92941944678b0e087f2532ceb99"
          }
        },
        "fd5b7bc9541d4c849f4bae1e25f59a7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
